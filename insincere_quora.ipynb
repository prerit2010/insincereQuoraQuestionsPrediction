{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "insincere_quora.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MOoJkiNcxr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "import re"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wPSy2Y4ftLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Conv1D\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from keras import Sequential\n",
        "from keras import Input as Kinput"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBnBxrhVxqpU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "dfe683ff-a8af-4f67-df54-53dd80307b3b"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices(), tf.test.gpu_device_name()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([name: \"/device:CPU:0\"\n",
              "  device_type: \"CPU\"\n",
              "  memory_limit: 268435456\n",
              "  locality {\n",
              "  }\n",
              "  incarnation: 11886033282141896260, name: \"/device:XLA_CPU:0\"\n",
              "  device_type: \"XLA_CPU\"\n",
              "  memory_limit: 17179869184\n",
              "  locality {\n",
              "  }\n",
              "  incarnation: 17107182767047603321\n",
              "  physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
              "  device_type: \"XLA_GPU\"\n",
              "  memory_limit: 17179869184\n",
              "  locality {\n",
              "  }\n",
              "  incarnation: 14446573696053546960\n",
              "  physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
              "  device_type: \"GPU\"\n",
              "  memory_limit: 11150726272\n",
              "  locality {\n",
              "    bus_id: 1\n",
              "    links {\n",
              "    }\n",
              "  }\n",
              "  incarnation: 4603618681831649000\n",
              "  physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"],\n",
              " '/device:GPU:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyJ2_p3YeZw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/data/insincereQuora/train.csv\")"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-_0JdHWeou6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1903735c-c0ba-4771-9c92-3981e2547e33"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1306122, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9X7b-eauA8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_to_word_list(text):\n",
        "    ''' Pre process and convert texts to a list of words '''\n",
        "    text = str(text)\n",
        "    text = text.lower()\n",
        "\n",
        "    # Clean the text\n",
        "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
        "    text = re.sub(r\":\", \" : \", text)\n",
        "    text = re.sub(r\" e g \", \" eg \", text)\n",
        "    text = re.sub(r\" b g \", \" bg \", text)\n",
        "    text = re.sub(r\" u s \", \" american \", text)\n",
        "    text = re.sub(r\"\\0s\", \"0\", text)\n",
        "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "    text = re.sub(r\"e - mail\", \"email\", text)\n",
        "    text = re.sub(r\"j k\", \"jk\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "\n",
        "    # text = text.split()\n",
        "\n",
        "    return text"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mG6S6MOtgXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['question_text'] = df['question_text'].apply(text_to_word_list)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blqassWGeqiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train, df_test = train_test_split(df, test_size=0.20, random_state=2018)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rbBiryslghe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_train, df_valid = train_test_split(df_train, test_size=0.10, random_state=2018)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A9WtF6ne50V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_length = 100\n",
        "embed_size = 300\n",
        "max_vocab_size = 50000"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-H2qzYCofTUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = df_train[\"question_text\"].fillna(\"_na_\").values\n",
        "test = df_test[\"question_text\"].fillna(\"_na_\").values\n",
        "# valid = df_valid[\"question_text\"].fillna(\"_na_\").values"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3FdV6ZGfcKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=max_vocab_size)\n",
        "tokenizer.fit_on_texts(list(train))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuTYRohufoqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X = tokenizer.texts_to_sequences(train)\n",
        "test_X = tokenizer.texts_to_sequences(test)\n",
        "# valid_X = tokenizer.texts_to_sequences(valid)\n",
        "\n",
        "## Pad the sentences \n",
        "train_X = pad_sequences(train_X, maxlen=max_length)\n",
        "test_X = pad_sequences(test_X, maxlen=max_length)\n",
        "# valid_X = pad_sequences(valid_X, maxlen=max_length)\n",
        "\n",
        "## Get the target values\n",
        "train_y = df_train['target'].values\n",
        "test_y = df_test['target'].values\n",
        "# valid_y = df_valid['target'].values"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnjm7npngYk9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "49c3aee0-b305-41d5-e7c7-8f4ad93b3c43"
      },
      "source": [
        "inp = Input(shape=(max_length,))\n",
        "x = Embedding(max_vocab_size, embed_size)(inp)\n",
        "x = Bidirectional(GRU(64, return_sequences=True))(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dense(16, activation=\"relu\")(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(1, activation=\"sigmoid\")(x)\n",
        "model = Model(inputs=inp, outputs=x)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "embedding_3 (Embedding)      (None, 100, 300)          15000000  \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 100, 128)          140160    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_3 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 16)                2064      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 15,142,241\n",
            "Trainable params: 15,142,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7ACJLUugFqb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "833e5b50-d564-4cc6-a2d3-e0b346ee2dc1"
      },
      "source": [
        "model.fit(train_X, train_y, batch_size=2048, epochs=2, validation_data=(test_X, test_y))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1044897 samples, validate on 261225 samples\n",
            "Epoch 1/2\n",
            "1044897/1044897 [==============================] - 1080s 1ms/step - loss: 0.1313 - accuracy: 0.9507 - val_loss: 0.1087 - val_accuracy: 0.9557\n",
            "Epoch 2/2\n",
            "1044897/1044897 [==============================] - 1072s 1ms/step - loss: 0.1067 - accuracy: 0.9573 - val_loss: 0.1073 - val_accuracy: 0.9574\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f0e6b1454e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Dd-98dph4sP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "59e0706d-225a-4680-fda7-82e711aec8ec"
      },
      "source": [
        "pred_prob = model.predict([test_X], batch_size=2048, verbose=1)\n",
        "max_acc = 0\n",
        "at_thresh = 0\n",
        "for thresh in np.arange(0.1, 0.701, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    acc = metrics.f1_score(test_y, (pred_prob>thresh).astype(int))\n",
        "    if acc > max_acc:\n",
        "      max_acc = acc\n",
        "      at_thresh = thresh\n",
        "print(\" Max F1 score is {0} found at threshold {1}\".format(max_acc, at_thresh))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "261225/261225 [==============================] - 47s 181us/step\n",
            " Max F1 score is 0.654288586106768 found at threshold 0.654288586106768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-8eS86Pm_ob",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "26af0497-b122-47ed-c3a6-0740262d9a4b"
      },
      "source": [
        "!wget -P /root/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-03 17:19:13--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.32.246\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.32.246|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘/root/input/GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  32.6MB/s    in 49s     \n",
            "\n",
            "2020-07-03 17:20:02 (32.3 MB/s) - ‘/root/input/GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzHMxacUnFYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install gensim\n",
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XV957059nKgg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "871a3adb-a5b5-415b-f9e1-87e0399e1fc2"
      },
      "source": [
        "EMBEDDING_FILE = '/root/input/GoogleNews-vectors-negative300.bin.gz' # from above\n",
        "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dug41Yn_nNqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lower down\n",
        "# remove punctutations\n",
        "# take ensemble of models\n",
        "# try lstm, gru\n",
        "# try conv layer after lstm / gru\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1ZxvnuUg09A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_vocab_size, len(word_index))\n",
        "embedding_matrix = np.random.normal(0, 1, (nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_vocab_size: continue\n",
        "    if word in word2vec.vocab:  \n",
        "      embedding_vector = word2vec[word]\n",
        "    else:\n",
        "      embedding_vector = None\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wbbLKV6hZZF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "482d1d50-631e-4e38-fa43-3365c5f81063"
      },
      "source": [
        "inp = Input(shape=(max_length,))\n",
        "x = Embedding(max_vocab_size, embed_size, weights=[embedding_matrix])(inp)\n",
        "x = Bidirectional(GRU(64, return_sequences=True))(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dense(16, activation=\"relu\")(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(1, activation=\"sigmoid\")(x)\n",
        "model = Model(inputs=inp, outputs=x)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "embedding_5 (Embedding)      (None, 100, 300)          15000000  \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, 100, 128)          140160    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_5 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 16)                2064      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 15,142,241\n",
            "Trainable params: 15,142,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3bSNI1niH7d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "3780130c-7da4-46f8-cb55-42a545b40b6a"
      },
      "source": [
        "model.fit(train_X, train_y, batch_size=2048, epochs=2, validation_data=(test_X, test_y))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1044897 samples, validate on 261225 samples\n",
            "Epoch 1/2\n",
            "1044897/1044897 [==============================] - 425s 407us/step - loss: 0.1367 - accuracy: 0.9470 - val_loss: 0.1082 - val_accuracy: 0.9564\n",
            "Epoch 2/2\n",
            "1044897/1044897 [==============================] - 419s 401us/step - loss: 0.1032 - accuracy: 0.9584 - val_loss: 0.1048 - val_accuracy: 0.9577\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f0e6d526208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhmOG2CEiTcF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "de4e833a-2624-4805-e0fd-e33b75363f95"
      },
      "source": [
        "pred_prob = model.predict([test_X], batch_size=2048, verbose=1)\n",
        "max_acc = 0\n",
        "at_thresh = 0\n",
        "for thresh in np.arange(0.1, 0.701, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    acc = metrics.f1_score(test_y, (pred_prob>thresh).astype(int))\n",
        "    if acc > max_acc:\n",
        "      max_acc = acc\n",
        "      at_thresh = thresh\n",
        "print(\" Max F1 score is {0} found at threshold {1}\".format(max_acc, at_thresh))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "261225/261225 [==============================] - 20s 75us/step\n",
            " Max F1 score is 0.657105092944121 found at threshold 0.657105092944121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXQIshA7ivmT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "e8850625-9683-4db8-be96-85f11b2a7d5a"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_vocab_size, embed_size, input_length = max_length, weights=[embedding_matrix]))\n",
        "# Bidirectional(GRU(64, return_sequences=True))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True, dropout_U = 0.2, dropout_W = 0.2)))  # returns a sequence of vectors of dimension 32\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True, dropout_U = 0.2, dropout_W = 0.2)))  # returns a sequence of vectors of dimension 32\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True, dropout_U = 0.2, dropout_W = 0.2)))  # return a single vector of dimension 32\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 100, 300)          15000000  \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 100, 128)          186880    \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 100, 128)          98816     \n",
            "_________________________________________________________________\n",
            "bidirectional_8 (Bidirection (None, 100, 128)          98816     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_6 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 15,388,673\n",
            "Trainable params: 15,388,673\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFCiJvzaurGU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "1b5b2742-515f-4540-d938-19612ed42eec"
      },
      "source": [
        "model.fit(train_X, train_y, batch_size=2048, epochs=2, validation_data=(test_X, test_y))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1044897 samples, validate on 261225 samples\n",
            "Epoch 1/2\n",
            "1044897/1044897 [==============================] - 1059s 1ms/step - loss: 0.1361 - accuracy: 0.9474 - val_loss: 0.1094 - val_accuracy: 0.9558\n",
            "Epoch 2/2\n",
            "1044897/1044897 [==============================] - 1058s 1ms/step - loss: 0.1084 - accuracy: 0.9554 - val_loss: 0.1062 - val_accuracy: 0.9568\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f0e6d526978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuwpUh9krlDT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "db4768a6-5c31-4b90-c963-cc03a507de08"
      },
      "source": [
        "pred_prob = model.predict([test_X], batch_size=2048, verbose=1)\n",
        "max_acc = 0\n",
        "at_thresh = 0\n",
        "for thresh in np.arange(0.1, 0.701, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    acc = metrics.f1_score(test_y, (pred_prob>thresh).astype(int))\n",
        "    if acc > max_acc:\n",
        "      max_acc = acc\n",
        "      at_thresh = thresh\n",
        "print(\" Max F1 score is {0} found at threshold {1}\".format(max_acc, at_thresh))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "261225/261225 [==============================] - 48s 183us/step\n",
            " Max F1 score is 0.6519388407650718 found at threshold 0.6519388407650718\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0VOZ2x4v8YX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}